/**
 * Real Parallel SQLite Test
 * Actually spawns separate Node.js processes to demonstrate true parallel scaling
 */

import { describe, it, beforeAll, afterAll } from 'vitest'
import { spawn } from 'child_process'
import { SQLiteStorage } from '../index.js'
import { brand } from '@bassline/core'
import { rmSync, mkdirSync, writeFileSync } from 'fs'
import { join } from 'path'

describe('SQLite Real Parallel Test', () => {
  const testDir = './test-data-real-parallel'
  
  beforeAll(() => {
    try {
      rmSync(testDir, { recursive: true, force: true })
    } catch (e) {}
    mkdirSync(testDir, { recursive: true })
    
    console.log('\nðŸš€ === SQLite REAL Parallel Test ===\n')
    console.log('This test actually spawns separate processes!\n')
  })
  
  afterAll(() => {
    rmSync(testDir, { recursive: true, force: true })
  })
  
  describe('Same Process (current simple-parallel behavior)', () => {
    it('should show CPU contention in same process', async () => {
      console.log('ðŸ“Š SAME PROCESS (what simple-parallel actually does):\n')
      
      const instanceCounts = [1, 2, 5, 10]
      const operationsPerInstance = 10000
      
      for (const count of instanceCounts) {
        const instances: SQLiteStorage[] = []
        
        // Create SQLite instances IN THE SAME PROCESS
        for (let i = 0; i < count; i++) {
          const storage = new SQLiteStorage({
            options: {
              dataDir: testDir,
              mode: 'sharded',
              synchronous: 'OFF'
            }
          })
          await storage.initialize()
          instances.push(storage)
        }
        
        const startTime = performance.now()
        
        // Run "in parallel" (but actually concurrent in same process)
        const promises = instances.map(async (storage, idx) => {
          const networkId = brand.networkId(`same-${idx}`)
          const groupId = brand.groupId(`group-${idx}`)
          
          await storage.saveNetworkState(networkId, {
            groups: new Map(),
            currentGroupId: 'root',
            rootGroupId: 'root'
          })
          
          for (let i = 0; i < operationsPerInstance; i++) {
            await storage.saveContactContent(
              networkId,
              groupId,
              brand.contactId(`c-${i % 100}`),
              { value: i }
            )
          }
        })
        
        await Promise.all(promises)
        const duration = performance.now() - startTime
        
        const totalOps = count * operationsPerInstance
        const opsPerSec = totalOps / duration * 1000
        
        console.log(`  ${count} instances in SAME process:`)
        console.log(`    Total: ${opsPerSec.toFixed(0)} ops/sec`)
        console.log(`    Per instance: ${(opsPerSec / count).toFixed(0)} ops/sec`)
        console.log(`    âš ï¸  All fighting for same CPU!\n`)
        
        for (const storage of instances) {
          await storage.close()
        }
      }
    })
  })
  
  describe('Separate Processes (true parallelism)', () => {
    it('should show linear scaling with separate processes', async () => {
      console.log('ðŸ”¥ SEPARATE PROCESSES (true parallelism):\n')
      
      // Create a worker script that will run in separate processes
      const workerScript = `
import { SQLiteStorage } from '${join(process.cwd(), 'dist/index.js')}'

const instanceId = process.argv[2]
const operations = parseInt(process.argv[3])
const testDir = process.argv[4]

async function run() {
  const storage = new SQLiteStorage({
    options: {
      dataDir: testDir,
      mode: 'sharded',
      synchronous: 'OFF'
    }
  })
  
  await storage.initialize()
  
  const networkId = 'network-' + instanceId
  const groupId = 'group-' + instanceId
  
  await storage.saveNetworkState(networkId, {
    groups: new Map(),
    currentGroupId: 'root',
    rootGroupId: 'root'
  })
  
  const start = Date.now()
  
  for (let i = 0; i < operations; i++) {
    await storage.saveContactContent(
      networkId,
      groupId,
      'contact-' + (i % 100),
      { value: i, process: instanceId }
    )
  }
  
  const duration = Date.now() - start
  const opsPerSec = operations / duration * 1000
  
  await storage.close()
  
  // Output results as JSON
  console.log(JSON.stringify({
    instanceId,
    operations,
    duration,
    opsPerSec
  }))
}

run().catch(console.error)
`
      
      const workerPath = join(testDir, 'worker.mjs')
      writeFileSync(workerPath, workerScript)
      
      const processCounts = [1, 2, 5, 10]
      const operationsPerProcess = 10000
      
      for (const count of processCounts) {
        console.log(`  Spawning ${count} SEPARATE processes...`)
        
        const startTime = Date.now()
        
        // Actually spawn separate Node.js processes!
        const promises = Array.from({ length: count }, (_, i) => 
          new Promise<any>((resolve, reject) => {
            const child = spawn('node', [
              workerPath,
              String(i),
              String(operationsPerProcess),
              join(testDir, `process-${i}`)
            ])
            
            let output = ''
            child.stdout.on('data', (data) => {
              output += data.toString()
            })
            
            child.stderr.on('data', (data) => {
              console.error(`Process ${i} error:`, data.toString())
            })
            
            child.on('close', (code) => {
              if (code === 0) {
                try {
                  // Parse the last line as JSON
                  const lines = output.trim().split('\n')
                  const result = JSON.parse(lines[lines.length - 1])
                  resolve(result)
                } catch (e) {
                  console.error(`Failed to parse output from process ${i}:`, output)
                  reject(e)
                }
              } else {
                reject(new Error(`Process ${i} exited with code ${code}`))
              }
            })
          })
        )
        
        try {
          const results = await Promise.all(promises)
          const totalDuration = Date.now() - startTime
          
          const totalOps = results.reduce((sum, r) => sum + r.operations, 0)
          const totalOpsPerSec = totalOps / totalDuration * 1000
          const avgOpsPerProcess = results.reduce((sum, r) => sum + r.opsPerSec, 0) / count
          
          console.log(`    Total: ${totalOpsPerSec.toFixed(0)} ops/sec`)
          console.log(`    Per process avg: ${avgOpsPerProcess.toFixed(0)} ops/sec`)
          console.log(`    âœ… Each process gets its own CPU!\n`)
        } catch (error) {
          console.error(`    âŒ Failed to run ${count} processes:`, error)
          console.log()
        }
      }
      
      console.log('  Note: If this fails, it\'s because the compiled dist/index.js doesn\'t exist.')
      console.log('  Run "pnpm build" first to compile the TypeScript.')
    }, 30000)
  })
  
  describe('The Key Difference', () => {
    it('should explain the crucial distinction', async () => {
      console.log('\nðŸ’¡ THE KEY DIFFERENCE:\n')
      
      console.log('Same Process (Promise.all):')
      console.log('  - All SQLite instances share one Node.js event loop')
      console.log('  - All C++ bindings run on same thread')
      console.log('  - CPU-bound operations block each other')
      console.log('  - Result: ~130K ops/sec total, divided among instances')
      
      console.log('\nSeparate Processes (spawn):')
      console.log('  - Each SQLite gets its own Node.js process')
      console.log('  - Each process gets its own CPU core')
      console.log('  - No blocking between instances')
      console.log('  - Result: ~130K ops/sec PER PROCESS')
      
      console.log('\nðŸŽ¯ For Bassline:')
      console.log('  - Each bridge should spawn its own process')
      console.log('  - Or use Worker threads with native SQLite bindings')
      console.log('  - This gives TRUE parallel execution')
      console.log('  - 20 bridges = 20 Ã— 130K = 2.6M ops/sec!')
    })
  })
})